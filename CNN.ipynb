{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae455b1-0ed1-49f1-b2fc-cb33898905be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread, imshow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "455d756d-2052-44b7-9a6d-03ca1ed2edab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2644/3964308832.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Load annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mlabel_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msub_dir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mant_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mlabel_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub_dir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Load data\n",
    "#\n",
    "\n",
    "img_dir = \"images/Images\"\n",
    "ant_dir = \"annotations/Annotation\"\n",
    "X=[] #input array\n",
    "Y=[] #output array\n",
    "\n",
    "bnd_dict = {}\n",
    "\n",
    "# Load annotations\n",
    "label_count = 0\n",
    "for sub_dir in os.listdir(ant_dir):\n",
    "    label_count += 1\n",
    "    label = sub_dir.split(\"-\")[1]\n",
    "    print(label)\n",
    "    path=os.path.join(ant_dir,sub_dir)\n",
    "    for ant in os.listdir(path):\n",
    "        if ant[0] != 'n': continue\n",
    "        tree = ET.parse(os.path.join(path,ant))\n",
    "        root = tree.getroot()\n",
    "        bndbox = root.find(\"object\").find(\"bndbox\")\n",
    "        xmin = int(bndbox.findtext(\"xmin\"))\n",
    "        ymin = int(bndbox.findtext(\"ymin\"))\n",
    "        xmax = int(bndbox.findtext(\"xmax\"))\n",
    "        ymax = int(bndbox.findtext(\"ymax\"))\n",
    "        bnd_dict[ant] = [xmin, ymin, xmax, ymax]\n",
    "    #if label_count >= 5: break\n",
    "        \n",
    "        \n",
    "# Load images      \n",
    "label_count = 0\n",
    "for sub_dir in os.listdir(img_dir):\n",
    "    label_count += 1\n",
    "    label = sub_dir.split(\"-\")[1]\n",
    "    #print(label)\n",
    "    path=os.path.join(img_dir,sub_dir)\n",
    "    for img in os.listdir(path):\n",
    "        if img[0] != 'n': continue\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        #imshow(img_array)\n",
    "        #plt.show()\n",
    "        bnd = bnd_dict[img.split(\".\")[0]]         \n",
    "        img_bnd = img_array[bnd[1]:bnd[3],bnd[0]:bnd[2]]  # Use bndbox to crop image\n",
    "        #imshow(img_bnd)\n",
    "        #plt.show()\n",
    "        #print(img_bnd)\n",
    "        img_resized=resize(img_bnd,(227, 227, 3))#(150,150,3))\n",
    "        #print(img_resized)\n",
    "        X.append(img_resized)#.flatten()) # don't flatten it if CNN\n",
    "        Y.append(label_count-1)\n",
    "        \n",
    "        img_fliplr = np.fliplr(img_resized)\n",
    "        X.append(img_fliplr)#.flatten())\n",
    "        Y.append(label_count-1)\n",
    "        \n",
    "        img_flipud = np.flipud(img_resized)\n",
    "        X.append(img_flipud)#.flatten())\n",
    "        Y.append(label_count-1)\n",
    "        \n",
    "    print(f'loaded category:{label} successfully')\n",
    "    #if label_count >= 5: break\n",
    "\n",
    "X=np.array(X)#.astype('float16')\n",
    "Y=np.array(Y)#.astype('float16')\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0458fa-f5a3-4f06-8a56-1b4cd3b49410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split, TensorDataset\n",
    "%matplotlib inline\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc68498-e3e1-42e4-8534-7380687eb94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Data shuffle and build dataloader\n",
    "#\n",
    "\n",
    "tensor_x = torch.Tensor(X) # transform to torch tensor\n",
    "tensor_x = torch.swapaxes(tensor_x, 2, 3)\n",
    "tensor_x = torch.swapaxes(tensor_x, 1, 2)\n",
    "print(tensor_x.size())\n",
    "tensor_y = torch.Tensor(Y).type(torch.LongTensor)\n",
    "print(tensor_y.size())\n",
    "\n",
    "dataset = TensorDataset(tensor_x,tensor_y)\n",
    "train_size = int(X.shape[0]*0.8)\n",
    "val_size = int(X.shape[0]*0.1)\n",
    "test_size = X.shape[0] - train_size - val_size\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "#passing the train, val and test datasets to the dataloader\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=64, shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46700673-b488-4a22-a4cc-2d11e1b659d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Train the model\n",
    "#\n",
    "\n",
    "\n",
    "device = 'cuda' # if you dont have a gpu, set device = cpu here\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19_bn', pretrained=True)\n",
    "model = model.to(device=device) #to send the model for training on either cuda or cpu\n",
    "\n",
    "## Loss and optimizer\n",
    "learning_rate = 1e-5\n",
    "load_model = True\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "val_acc = []\n",
    "tr_loss = []\n",
    "\n",
    "for epoch in range(50): # How many epochs?\n",
    "    loss_ep = 0\n",
    "    \n",
    "    print(\"learning rate: \", learning_rate)\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_dl):\n",
    "        #print(data.shape)\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr= learning_rate)\n",
    "        ## Forward Pass\n",
    "        optimizer.zero_grad()\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ep += loss.item()\n",
    "    print(f\"Loss in epoch {epoch} :::: {loss_ep/len(train_dl)}\")\n",
    "    tr_loss.append(loss_ep/len(train_dl))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        for batch_idx, (data,targets) in enumerate(val_dl):\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            ## Forward Pass\n",
    "            scores = model(data)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == targets).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        print(\n",
    "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\"\n",
    "        )\n",
    "        val_acc.append(float(num_correct) / float(num_samples) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc044d-06ca-4fe6-838a-24a39a58f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots out train loss and validation accuracy\n",
    "plt.title(\"VGG Train loss\")\n",
    "plt.plot(list(range(1, len(tr_loss)+1)), tr_loss)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"VGG Validation accuracy\")\n",
    "plt.plot(list(range(1, len(val_acc)+1)), val_acc)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d6d8e-2848-407b-bcb3-036d9e3b6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints out test accuracy\n",
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    for batch_idx, (data,targets) in enumerate(test_dl):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        ## Forward Pass\n",
    "        scores = model(data)\n",
    "        _, predictions = scores.max(1)\n",
    "        num_correct += (predictions == targets).sum()\n",
    "        num_samples += predictions.size(0)\n",
    "    print(\n",
    "        f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
